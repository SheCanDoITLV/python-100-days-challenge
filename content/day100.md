# 🎉 Day 100 Challenge: Your Final Python Victory Lap 🏆

**Congratulations, Python Champion!** 🎉 You've reached the final day of the **100 Days of Python Challenge**, and this is your moment to shine! You've earned your virtual trophy 🏆 (we'll work on a real one next time 😉). Now, let’s wrap it up with an exciting and practical challenge: a **Price Scraper** that could save you money! 💸

---

### 🥳 What You'll Create Today:
A Python script that:
1. Tracks product prices on a website.
2. Alerts you via email when the price drops below your desired amount. 📩
3. Keeps you informed of amazing deals, so you never miss out! 🌟

**Heads-Up:** Scraping any online store can get tricky as they block bots quickly. Instead, pick a product website like [Fashionnova](https://www.fashionnova.com), Zalando, eBay, or your favorite online store.

---

### 🛠️ Your Challenge Objectives:
1. **Use a Dictionary**: Store product details, including:
   - Product name 🏷️
   - Current price 💰
   - The "I'll buy it!" price threshold.
   
2. **Daily Price Tracking**:
   - Scrape the product page for updated prices.
   - Compare the current price with your desired price.
   
3. **Automated Email Alert**:
   - Send an email with:
     - Product name and a direct link 🔗
     - Your desired price vs. the current price.
     - A fun, motivational message to seal the deal!

---

### 🧩 Sample Code (VSCode Version)

Here's your starting point! Customize this for your favorite products and websites.

<img id="image" src="assets/day100_1.png" alt="day100 image" width="720">

<img id="image" src="assets/day100_2.png" alt="day100 image" width="720">

---

### 🛠️ Steps to Succeed:
1. **Set Up Your Environment**:
   - Install required libraries: `requests`, `beautifulsoup4`, and `schedule`.
   - Configure your email credentials in an `.env` file.

2. **Pick Your Product**:
   - Replace the URL with your favorite store's product page. 🛒
   - Update HTML classes in the scraper to match the website's structure.

3. **Test Your Code**:
   - Ensure it scrapes data and sends email alerts correctly. 🛠️

4. **Deploy**:
   - For continuous scraping, consider hosting the script on a cloud platform or using a local scheduler.

---

### 🎯 Final Thoughts:
- If you enjoyed this challenge, **share your results** with friends or colleagues. Collaboration makes learning fun! 🤝
- Don’t forget to complete the survey and help us create even better courses in the future. Your feedback is gold! ✨

Now, go forth and conquer this challenge like the Python pro you are! 🐍💪

---

## Solution (No Peeking!)

<details>
<summary>👀 Answer</summary>

```python
from bs4 import BeautifulSoup
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
import time, schedule, os, smtplib, requests
from dotenv import load_dotenv

load_dotenv(dotenv_path='python-dotenv/.env')

sender_password = os.getenv('mailPassword')
sender_email = os.getenv('mailUsername')
receiver_email = "alise@shecandoit.lv"
desired_price = 100

def send_email(subject, body):
    try:
        with smtplib.SMTP("smtp.gmail.com", 587) as server:
            server.starttls()
            server.login(sender_email, sender_password)
            msg = MIMEMultipart()
            msg['From'] = sender_email
            msg['To'] = receiver_email
            msg['Subject'] = subject
            msg.attach(MIMEText(body, 'html'))
            server.send_message(msg)
        print(f"✅ Email sent: {subject}")
    except Exception as e:
        print(f"❌ Email sending failed: {e}")

def format_email(product_info):
    return f"""
    <html>
        <body>
            <h2>🔥 Price Alert: {product_info['name']} is now {product_info['current_price']}€!</h2>
            <p>🎯 Your desired price: <b>{desired_price}€</b></p>
            <p>💰 Current price: <b>{product_info['current_price']}€</b></p>
            <p>👉 <a href="{product_info['link']}">Check it out here!</a></p>
        </body>
    </html>
    """

def fetch_page_content(url):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return response.text
    except requests.exceptions.RequestException as e:
        print(f"❌ Failed to fetch the website: {e}")
        return None

def extract_product_details(item):
    try:
        # Extract link and name
        link_tag = item.find("a", class_="hover:underline")
        if not (link_tag and link_tag['href'] and link_tag.text.strip()):
            return None

        product_name = link_tag.text.strip()
        product_link = f"https://www.fashionnova.com{link_tag['href']}"

        # Extract price
        price_tag = item.find("div", class_="body-md-bold")
        if not (price_tag and price_tag.text.strip()):
            print(f"⚠️ Missing price for product: {product_name}")
            return None

        current_price = price_tag.text.strip().replace('$', '').replace(',', '')
        try:
            current_price = float(current_price)
        except ValueError:
            print(f"⚠️ Invalid price format: {price_tag.text.strip()} for product {product_name}")
            return None

        return {
            'name': product_name,
            'link': product_link,
            'current_price': current_price
        }
    except Exception as e:
        print(f"Error extracting product details: {e}")
        return None

def scrape_clothing_items(url):
    html_content = fetch_page_content(url)
    if not html_content:
        return []

    soup = BeautifulSoup(html_content, 'html.parser')
    clothing_items = []

    for item in soup.find_all("div", class_="product-item"):
        product = extract_product_details(item)
        if product:
            clothing_items.append(product)

    return clothing_items

def check_prices():
    url = "https://www.fashionnova.com/collections/sale"
    products = scrape_clothing_items(url)
    for product in products:
        print(f"Product: {product}")
        if product['current_price'] < desired_price:
            email_body = format_email(product)
            send_email(f"🔥 Price Alert: {product['name']}!", email_body)

schedule.every(1).minutes.do(check_prices)

while True:
    schedule.run_pending()
    time.sleep(1)
```

</details>